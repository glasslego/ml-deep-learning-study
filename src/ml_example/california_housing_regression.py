"""
ì‹¤ìŠµ 1: ìº˜ë¦¬í¬ë‹ˆì•„ ì§‘ê°’ íšŒê·€ ë¶„ì„

ì„ í˜• íšŒê·€ ëª¨ë¸ì˜ í•µì‹¬ ê°œë…:
- ë…ë¦½ë³€ìˆ˜(X)ì™€ ì¢…ì†ë³€ìˆ˜(y) ê°„ì˜ ì„ í˜• ê´€ê³„ë¥¼ ëª¨ë¸ë§
- ì†ì‹¤ í•¨ìˆ˜: í‰ê·  ì œê³± ì˜¤ì°¨(MSE) = (1/n) * Î£(y_actual - y_predicted)Â²
- ìµœì í™”: ê²½ì‚¬í•˜ê°•ë²•ì„ í†µí•´ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ìµœì†Œí™”í•˜ëŠ” ê°€ì¤‘ì¹˜ ì°¾ê¸°
- í‰ê°€ ì§€í‘œ: RÂ² ìŠ¤ì½”ì–´(ê²°ì •ê³„ìˆ˜), MAE(í‰ê·  ì ˆëŒ€ ì˜¤ì°¨), RMSE(í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨)
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

def load_and_explore_data():
    """
    ìº˜ë¦¬í¬ë‹ˆì•„ ì£¼íƒ ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰ì  ë°ì´í„° ë¶„ì„(EDA)
    
    ë°ì´í„°ì…‹ íŠ¹ì§•:
    - MedInc: ë¸”ë¡ ê·¸ë£¹ì˜ ì¤‘ìœ„ì†Œë“ (ë§Œ ë‹¬ëŸ¬ ë‹¨ìœ„)
    - HouseAge: ë¸”ë¡ ê·¸ë£¹ ë‚´ ì£¼íƒì˜ ì¤‘ìœ„ ì—°ë ¹
    - AveRooms: í‰ê·  ë°© ìˆ˜
    - AveBedrms: í‰ê·  ì¹¨ì‹¤ ìˆ˜
    - Population: ë¸”ë¡ ê·¸ë£¹ ì¸êµ¬
    - AveOccup: í‰ê·  ê°€êµ¬ì› ìˆ˜
    - Latitude: ìœ„ë„
    - Longitude: ê²½ë„
    - Target: ì£¼íƒ ê°€ê²© ì¤‘ìœ„ê°’ (ì‹­ë§Œ ë‹¬ëŸ¬ ë‹¨ìœ„)
    """
    print("=== ìº˜ë¦¬í¬ë‹ˆì•„ ì£¼íƒ ë°ì´í„° ë¡œë“œ ===")
    
    # ë°ì´í„° ë¡œë“œ
    housing = fetch_california_housing()
    X, y = housing.data, housing.target
    
    # DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë°ì´í„° ë¶„ì„ ìš©ì´ì„± ì¦ëŒ€
    df = pd.DataFrame(X, columns=housing.feature_names)
    df['target'] = y
    
    print(f"ë°ì´í„° í˜•íƒœ: {df.shape}")
    print(f"í”¼ì²˜ëª…: {list(housing.feature_names)}")
    print("\n=== ê¸°ìˆ  í†µê³„ ===")
    print(df.describe())
    
    # ê²°ì¸¡ê°’ í™•ì¸
    print(f"\nê²°ì¸¡ê°’: {df.isnull().sum().sum()}ê°œ")
    
    return X, y, df

def visualize_data(df):
    """
    ë°ì´í„° ì‹œê°í™”ë¥¼ í†µí•œ íŒ¨í„´ ë¶„ì„
    - íˆìŠ¤í† ê·¸ë¨: ê° ë³€ìˆ˜ì˜ ë¶„í¬ í™•ì¸
    - ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ: ë³€ìˆ˜ ê°„ ì„ í˜• ê´€ê³„ íŒŒì•…
    - ì‚°ì ë„: íƒ€ê²Ÿ ë³€ìˆ˜ì™€ ì£¼ìš” í”¼ì²˜ ê°„ ê´€ê³„ ì‹œê°í™”
    """
    plt.figure(figsize=(15, 10))
    
    # 1. íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„í¬
    plt.subplot(2, 3, 1)
    plt.hist(df['target'], bins=50, alpha=0.7, color='skyblue')
    plt.title('ì£¼íƒ ê°€ê²© ë¶„í¬')
    plt.xlabel('ê°€ê²© (ì‹­ë§Œ ë‹¬ëŸ¬)')
    plt.ylabel('ë¹ˆë„')
    
    # 2. ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
    plt.subplot(2, 3, 2)
    corr_matrix = df.corr()
    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')
    plt.title('í”¼ì²˜ ê°„ ìƒê´€ê´€ê³„')
    
    # 3-6. ì£¼ìš” í”¼ì²˜ì™€ íƒ€ê²Ÿ ë³€ìˆ˜ ê°„ ê´€ê³„
    important_features = ['MedInc', 'HouseAge', 'AveRooms', 'Population']
    for i, feature in enumerate(important_features):
        plt.subplot(2, 3, i+3)
        plt.scatter(df[feature], df['target'], alpha=0.5, s=1)
        plt.xlabel(feature)
        plt.ylabel('ì£¼íƒ ê°€ê²©')
        plt.title(f'{feature} vs ì£¼íƒ ê°€ê²©')
    
    plt.tight_layout()
    plt.savefig('california_housing_eda.png', dpi=300, bbox_inches='tight')
    plt.show()

def build_and_evaluate_model(X, y):
    """
    ì„ í˜• íšŒê·€ ëª¨ë¸ êµ¬ì¶• ë° í‰ê°€
    
    ëª¨ë¸ í•™ìŠµ ê³¼ì •:
    1. ë°ì´í„° ë¶„í• : í•™ìŠµìš© 80%, í…ŒìŠ¤íŠ¸ìš© 20%
    2. í”¼ì²˜ ìŠ¤ì¼€ì¼ë§: StandardScalerë¡œ ì •ê·œí™” (í‰ê· =0, í‘œì¤€í¸ì°¨=1)
    3. ëª¨ë¸ í•™ìŠµ: ìµœì†Œì œê³±ë²•ìœ¼ë¡œ ìµœì  ê°€ì¤‘ì¹˜ ê³„ì‚°
    4. ì„±ëŠ¥ í‰ê°€: ì—¬ëŸ¬ ì§€í‘œë¡œ ëª¨ë¸ ì„±ëŠ¥ ì¢…í•© í‰ê°€
    """
    print("\n=== ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ===")
    
    # 1. ë°ì´í„° ë¶„í•  (stratified samplingì€ íšŒê·€ì—ì„œ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ random_stateë¡œ ì¬í˜„ì„± í™•ë³´)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    print(f"í•™ìŠµ ë°ì´í„°: {X_train.shape}, í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape}")
    
    # 2. í”¼ì²˜ ìŠ¤ì¼€ì¼ë§ (ì„ í˜• íšŒê·€ì—ì„œ ìŠ¤ì¼€ì¼ë§ì€ í•´ì„ì— ì˜í–¥ì„ ì£¼ì§€ë§Œ ì„±ëŠ¥ í–¥ìƒì— ë„ì›€)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # 3. ì„ í˜• íšŒê·€ ëª¨ë¸ í•™ìŠµ
    # y = Î²â‚€ + Î²â‚xâ‚ + Î²â‚‚xâ‚‚ + ... + Î²â‚™xâ‚™ + Îµ
    # ëª©í‘œ: Î£(yáµ¢ - Å·áµ¢)Â² ìµœì†Œí™”í•˜ëŠ” Î² ì°¾ê¸°
    model = LinearRegression()
    model.fit(X_train_scaled, y_train)
    
    # 4. ì˜ˆì¸¡ ìˆ˜í–‰
    y_train_pred = model.predict(X_train_scaled)
    y_test_pred = model.predict(X_test_scaled)
    
    # 5. ì„±ëŠ¥ í‰ê°€ ì§€í‘œ ê³„ì‚°
    train_r2 = r2_score(y_train, y_train_pred)
    test_r2 = r2_score(y_test, y_test_pred)
    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
    train_mae = mean_absolute_error(y_train, y_train_pred)
    test_mae = mean_absolute_error(y_test, y_test_pred)
    
    print(f"\n=== ì„±ëŠ¥ ì§€í‘œ ===")
    print(f"RÂ² Score:")
    print(f"  í•™ìŠµ: {train_r2:.4f}")
    print(f"  í…ŒìŠ¤íŠ¸: {test_r2:.4f}")
    print(f"RMSE (ì‹­ë§Œ ë‹¬ëŸ¬):")
    print(f"  í•™ìŠµ: {train_rmse:.4f}")
    print(f"  í…ŒìŠ¤íŠ¸: {test_rmse:.4f}")
    print(f"MAE (ì‹­ë§Œ ë‹¬ëŸ¬):")
    print(f"  í•™ìŠµ: {train_mae:.4f}")
    print(f"  í…ŒìŠ¤íŠ¸: {test_mae:.4f}")
    
    # RÂ² í•´ì„: 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ (0.6 ì´ìƒì´ë©´ ì–‘í˜¸)
    # RMSE í•´ì„: ì‹¤ì œ ê°€ê²©ê³¼ ì˜ˆì¸¡ ê°€ê²©ì˜ í‰ê· ì ì¸ ì°¨ì´
    # MAE í•´ì„: ì ˆëŒ€ì ì¸ ì˜ˆì¸¡ ì˜¤ì°¨ì˜ í‰ê· 
    
    return model, scaler, (X_test_scaled, y_test, y_test_pred)

def analyze_model_coefficients(model, feature_names):
    """
    ì„ í˜• íšŒê·€ ëª¨ë¸ì˜ ê³„ìˆ˜ ë¶„ì„
    - ê° í”¼ì²˜ì˜ ì˜í–¥ë ¥ê³¼ ë°©í–¥ì„± íŒŒì•…
    - ì–‘ì˜ ê³„ìˆ˜: í”¼ì²˜ ê°’ì´ ì¦ê°€í•˜ë©´ íƒ€ê²Ÿë„ ì¦ê°€
    - ìŒì˜ ê³„ìˆ˜: í”¼ì²˜ ê°’ì´ ì¦ê°€í•˜ë©´ íƒ€ê²Ÿì€ ê°ì†Œ
    """
    print("\n=== ëª¨ë¸ ê³„ìˆ˜ ë¶„ì„ ===")
    
    coefficients = pd.DataFrame({
        'Feature': feature_names,
        'Coefficient': model.coef_,
        'Abs_Coefficient': np.abs(model.coef_)
    }).sort_values('Abs_Coefficient', ascending=False)
    
    print("í”¼ì²˜ë³„ ì˜í–¥ë ¥ (ì ˆëŒ“ê°’ ê¸°ì¤€ ì •ë ¬):")
    for _, row in coefficients.iterrows():
        direction = "ì¦ê°€" if row['Coefficient'] > 0 else "ê°ì†Œ"
        print(f"  {row['Feature']:12}: {row['Coefficient']:8.4f} ({direction} íš¨ê³¼)")
    
    print(f"\nì ˆí¸(intercept): {model.intercept_:.4f}")
    
    # ì‹œê°í™”
    plt.figure(figsize=(10, 6))
    colors = ['red' if c < 0 else 'blue' for c in coefficients['Coefficient']]
    plt.barh(coefficients['Feature'], coefficients['Coefficient'], color=colors)
    plt.xlabel('ê³„ìˆ˜ ê°’')
    plt.title('ì„ í˜• íšŒê·€ ëª¨ë¸ì˜ í”¼ì²˜ë³„ ê³„ìˆ˜')
    plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)
    plt.tight_layout()
    plt.savefig('linear_regression_coefficients.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    return coefficients

def plot_predictions(X_test, y_test, y_pred):
    """
    ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”
    - ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’ ì‚°ì ë„
    - ì™„ë²½í•œ ì˜ˆì¸¡ì„  (y=x)ê³¼ì˜ ë¹„êµ
    - ì”ì°¨(residual) ë¶„ì„ì„ í†µí•œ ëª¨ë¸ ì§„ë‹¨
    """
    plt.figure(figsize=(12, 4))
    
    # 1. ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’
    plt.subplot(1, 2, 1)
    plt.scatter(y_test, y_pred, alpha=0.6, s=20)
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
    plt.xlabel('ì‹¤ì œ ê°€ê²©')
    plt.ylabel('ì˜ˆì¸¡ ê°€ê²©')
    plt.title('ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’')
    plt.text(0.05, 0.95, f'RÂ² = {r2_score(y_test, y_pred):.3f}', 
             transform=plt.gca().transAxes, bbox=dict(boxstyle='round', facecolor='wheat'))
    
    # 2. ì”ì°¨ ë¶„ì„ (Residual Plot)
    plt.subplot(1, 2, 2)
    residuals = y_test - y_pred
    plt.scatter(y_pred, residuals, alpha=0.6, s=20)
    plt.axhline(y=0, color='r', linestyle='--')
    plt.xlabel('ì˜ˆì¸¡ê°’')
    plt.ylabel('ì”ì°¨ (ì‹¤ì œê°’ - ì˜ˆì¸¡ê°’)')
    plt.title('ì”ì°¨ í”Œë¡¯')
    
    # ì”ì°¨ ë¶„ì„ í•´ì„:
    # - ì”ì°¨ê°€ 0 ì£¼ìœ„ì— ëœë¤í•˜ê²Œ ë¶„í¬ â†’ ì¢‹ì€ ëª¨ë¸
    # - íŒ¨í„´ì´ ë³´ì„ â†’ ë¹„ì„ í˜•ì„± ì¡´ì¬í•˜ê±°ë‚˜ ì¤‘ìš”í•œ í”¼ì²˜ ëˆ„ë½
    # - ë¶„ì‚°ì´ ì¼ì •í•˜ì§€ ì•ŠìŒ â†’ ì´ë¶„ì‚°ì„± ë¬¸ì œ
    
    plt.tight_layout()
    plt.savefig('prediction_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()

def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    """
    print("ğŸ  ìº˜ë¦¬í¬ë‹ˆì•„ ì£¼íƒ ê°€ê²© ì˜ˆì¸¡ - ì„ í˜• íšŒê·€ ë¶„ì„")
    print("=" * 60)
    
    # 1. ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰
    X, y, df = load_and_explore_data()
    
    # 2. ë°ì´í„° ì‹œê°í™”
    visualize_data(df)
    
    # 3. ëª¨ë¸ êµ¬ì¶• ë° í‰ê°€
    model, scaler, test_results = build_and_evaluate_model(X, y)
    X_test_scaled, y_test, y_test_pred = test_results
    
    # 4. ëª¨ë¸ ê³„ìˆ˜ ë¶„ì„
    feature_names = fetch_california_housing().feature_names
    coefficients = analyze_model_coefficients(model, feature_names)
    
    # 5. ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”
    plot_predictions(X_test_scaled, y_test, y_test_pred)
    
    print("\n" + "=" * 60)
    print("âœ… ë¶„ì„ ì™„ë£Œ!")
    print("ğŸ“Š ìƒì„±ëœ ì‹œê°í™” íŒŒì¼:")
    print("   - california_housing_eda.png")
    print("   - linear_regression_coefficients.png") 
    print("   - prediction_analysis.png")
    
    # ëª¨ë¸ í•´ì„ ìš”ì•½
    print("\nğŸ“ˆ ì£¼ìš” ì¸ì‚¬ì´íŠ¸:")
    print("1. MedInc(ì¤‘ìœ„ì†Œë“)ì´ ê°€ì¥ í° ì–‘ì˜ ì˜í–¥")
    print("2. ìœ„ì¹˜(ìœ„ë„/ê²½ë„)ê°€ ê°€ê²©ì— ì¤‘ìš”í•œ ì˜í–¥")
    print("3. ì„ í˜• íšŒê·€ë¡œë„ ì•½ 60-67%ì˜ ë¶„ì‚° ì„¤ëª… ê°€ëŠ¥")
    
    return model, scaler, coefficients

if __name__ == "__main__":
    model, scaler, coefficients = main()