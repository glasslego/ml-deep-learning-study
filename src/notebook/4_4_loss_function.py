import matplotlib.pyplot as plt
import numpy as np

# í•œê¸€ í°íŠ¸ ì„¤ì • (MacOS ê¸°ì¤€)
plt.rcParams["font.family"] = "AppleGothic"


def visualize_binary_cross_entropy():
    """ì´ì§„ êµì°¨ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤ í•¨ìˆ˜ ì‹œê°í™”"""
    print("=== ì´ì§„ êµì°¨ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤ í•¨ìˆ˜ ===")
    print("Log Loss ì‹œê°í™”: -log(p) í˜•íƒœì˜ ì†ì‹¤ í•¨ìˆ˜")
    print()

    # ì˜ˆì¸¡ í™•ë¥  ë²”ìœ„
    y_pred = np.linspace(0.01, 0.99, 100)

    # y=1ì¼ ë•Œ ì†ì‹¤: -log(Å·)
    loss_y1 = -np.log(y_pred)

    # y=0ì¼ ë•Œ ì†ì‹¤: -log(1-Å·)
    loss_y0 = -np.log(1 - y_pred)

    plt.figure(figsize=(12, 5))

    # y=1ì¼ ë•Œ
    plt.subplot(1, 2, 1)
    plt.plot(y_pred, loss_y1, linewidth=3, color="#e74c3c")
    plt.xlabel("ì˜ˆì¸¡ í™•ë¥  (Å·)", fontsize=12)
    plt.ylabel("Loss", fontsize=12)
    plt.title("ì‹¤ì œ ë ˆì´ë¸” y = 1ì¼ ë•Œ", fontsize=14, fontweight="bold")
    plt.grid(True, alpha=0.3)
    plt.axvline(x=1.0, color="green", linestyle="--", alpha=0.5, label="ì™„ë²½í•œ ì˜ˆì¸¡")
    plt.legend()

    # y=0ì¼ ë•Œ
    plt.subplot(1, 2, 2)
    plt.plot(y_pred, loss_y0, linewidth=3, color="#3498db")
    plt.xlabel("ì˜ˆì¸¡ í™•ë¥  (Å·)", fontsize=12)
    plt.ylabel("Loss", fontsize=12)
    plt.title("ì‹¤ì œ ë ˆì´ë¸” y = 0ì¼ ë•Œ", fontsize=14, fontweight="bold")
    plt.grid(True, alpha=0.3)
    plt.axvline(x=0.0, color="green", linestyle="--", alpha=0.5, label="ì™„ë²½í•œ ì˜ˆì¸¡")
    plt.legend()

    plt.tight_layout()
    plt.show()

    print("âœ… ì‹œê°í™” ì™„ë£Œ!")
    print("- ì‹¤ì œê°’ì´ 1ì¼ ë•Œ: ì˜ˆì¸¡ í™•ë¥ ì´ 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì†ì‹¤ì´ 0ì— ê°€ê¹Œì›Œì§")
    print("- ì‹¤ì œê°’ì´ 0ì¼ ë•Œ: ì˜ˆì¸¡ í™•ë¥ ì´ 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì†ì‹¤ì´ 0ì— ê°€ê¹Œì›Œì§")
    print("- ì˜ëª» ì˜ˆì¸¡í• ìˆ˜ë¡ ì†ì‹¤ì´ ê¸‰ê²©íˆ ì¦ê°€í•¨")
    print()


# PyTorch ì˜ˆì œëŠ” í˜¸í™˜ì„± ë¬¸ì œë¡œ ì£¼ì„ ì²˜ë¦¬
# import torch
# import torch.nn as nn


def pytorch_explanation():
    """PyTorch ì†ì‹¤ í•¨ìˆ˜ ì„¤ëª…"""
    print("=" * 50)
    print("PyTorch Loss Functions (ì½”ë“œ ì˜ˆì œ)")
    print("=" * 50)

    print("\nğŸ’¡ PyTorch ì£¼ìš” ì†ì‹¤ í•¨ìˆ˜:")
    print("   1. BCEWithLogitsLoss: ì´ì§„ ë¶„ë¥˜ (Sigmoid + BCE)")
    print("   2. CrossEntropyLoss: ë‹¤ì¤‘ ë¶„ë¥˜ (Softmax + CE)")
    print("   3. MSELoss: íšŒê·€ (í‰ê·  ì œê³± ì˜¤ì°¨)")

    print("\nğŸ“ PyTorch ì´ì§„ ë¶„ë¥˜ ì˜ˆì œ ì½”ë“œ:")
    print("```python")
    print("import torch")
    print("import torch.nn as nn")
    print()
    print("# BCEWithLogitsLoss ì‚¬ìš©")
    print("criterion = nn.BCEWithLogitsLoss()")
    print("logits = torch.tensor([2.5, -1.0, 0.5, -3.0])")
    print("labels = torch.tensor([1.0, 0.0, 1.0, 0.0])")
    print("loss = criterion(logits, labels)")
    print("```")

    print("\nğŸ“ PyTorch ë‹¤ì¤‘ ë¶„ë¥˜ ì˜ˆì œ ì½”ë“œ:")
    print("```python")
    print("# CrossEntropyLoss ì‚¬ìš©")
    print("criterion = nn.CrossEntropyLoss()")
    print("logits = torch.tensor([[2.0, 1.0, 0.1], [0.5, 2.5, 1.0]])")
    print("labels = torch.tensor([0, 1])  # í´ë˜ìŠ¤ ì¸ë±ìŠ¤")
    print("loss = criterion(logits, labels)")
    print("```")


def compare_frameworks():
    """í”„ë ˆì„ì›Œí¬ ë¹„êµ"""
    print("\n" + "=" * 50)
    print("PyTorch vs TensorFlow ì†ì‹¤ í•¨ìˆ˜")
    print("=" * 50)

    print("\nğŸ“Š ì´ì§„ ë¶„ë¥˜ (Binary Classification)")
    print("   PyTorch:")
    print("   â†’ nn.BCEWithLogitsLoss()")
    print("   â†’ ë¡œì§“ + ë ˆì´ë¸” ì§ì ‘ ì…ë ¥")
    print()
    print("   TensorFlow:")
    print("   â†’ BinaryCrossentropy(from_logits=True)")
    print("   â†’ from_logits íŒŒë¼ë¯¸í„°ë¡œ ì œì–´")

    print("\nğŸ“Š ë‹¤ì¤‘ ë¶„ë¥˜ (Multi-class Classification)")
    print("   PyTorch:")
    print("   â†’ nn.CrossEntropyLoss()")
    print("   â†’ ì •ìˆ˜ ë ˆì´ë¸” (0, 1, 2, ...)")
    print()
    print("   TensorFlow:")
    print("   â†’ SparseCategoricalCrossentropy(from_logits=True)")
    print("   â†’ ì •ìˆ˜ ë ˆì´ë¸” or CategoricalCrossentropy (one-hot)")


# TensorFlowëŠ” AVX ì§€ì› ë¬¸ì œë¡œ ì£¼ì„ ì²˜ë¦¬
# import tensorflow as tf
# from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy


def tensorflow_explanation():
    """TensorFlow ì†ì‹¤ í•¨ìˆ˜ ì„¤ëª…"""
    print("=" * 50)
    print("TensorFlow Loss Functions (ì½”ë“œ ì˜ˆì œ)")
    print("=" * 50)

    print("\nğŸ’¡ TensorFlow ì£¼ìš” ì†ì‹¤ í•¨ìˆ˜:")
    print("   1. BinaryCrossentropy: ì´ì§„ ë¶„ë¥˜")
    print("   2. CategoricalCrossentropy: ë‹¤ì¤‘ ë¶„ë¥˜ (one-hot)")
    print("   3. SparseCategoricalCrossentropy: ë‹¤ì¤‘ ë¶„ë¥˜ (ì •ìˆ˜)")
    print("   4. MeanSquaredError: íšŒê·€")

    print("\nğŸ“ TensorFlow ì´ì§„ ë¶„ë¥˜ ì˜ˆì œ ì½”ë“œ:")
    print("```python")
    print("import tensorflow as tf")
    print("from tensorflow.keras.losses import BinaryCrossentropy")
    print()
    print("# BinaryCrossentropy ì‚¬ìš©")
    print("loss_fn = BinaryCrossentropy(from_logits=True)")
    print("logits = tf.constant([2.5, -1.0, 0.5, -3.0])")
    print("labels = tf.constant([1.0, 0.0, 1.0, 0.0])")
    print("loss = loss_fn(labels, logits)")
    print("```")

    print("\nğŸ“ TensorFlow ë‹¤ì¤‘ ë¶„ë¥˜ ì˜ˆì œ ì½”ë“œ:")
    print("```python")
    print("# SparseCategoricalCrossentropy ì‚¬ìš© (ë” í¸ë¦¬)")
    print("loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)")
    print("logits = tf.constant([[2.0, 1.0, 0.1], [0.5, 2.5, 1.0]])")
    print("labels = tf.constant([0, 1])  # ì •ìˆ˜ ë ˆì´ë¸”")
    print("loss = loss_fn(labels, logits)")
    print("```")


def main():
    """ë©”ì¸ í•¨ìˆ˜: ì†ì‹¤ í•¨ìˆ˜ ì‹œê°í™” ì‹¤í–‰"""
    print("ğŸ“ˆ Binary Cross-Entropy Loss Function ê°€ì´ë“œ ğŸ“ˆ")
    print("=" * 60)
    print()

    visualize_binary_cross_entropy()

    print("=" * 60)
    print("ğŸ‰ ì†ì‹¤ í•¨ìˆ˜ ì‹œê°í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰")
    print("=" * 60)

    print("\nğŸ”¥ PyTorch ì†ì‹¤ í•¨ìˆ˜ ì˜ˆì œ\n")

    # PyTorch ì˜ˆì œ (ì„¤ëª…ë§Œ)
    pytorch_explanation()

    # í”„ë ˆì„ì›Œí¬ ë¹„êµ
    compare_frameworks()

    print("\nğŸ”¥ TensorFlow ì†ì‹¤ í•¨ìˆ˜ ì˜ˆì œ\n")

    # TensorFlow ì˜ˆì œ (ì„¤ëª…ë§Œ)
    tensorflow_explanation()

    print("\n" + "=" * 50)
    print("âœ… ëª¨ë“  ì˜ˆì œ ì™„ë£Œ!")
    print("=" * 50 + "\n")


if __name__ == "__main__":
    main()
